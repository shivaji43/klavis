{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/togethercomputer/together-cookbook/blob/main/Agents/KlavisAI/Use_Klavis_with_Together.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Together AI + Klavis AI Integration\n",
        "\n",
        "# <img src=\"../../static/togetherai-klavis.png\" width=\"700\">\n",
        "\n",
        "In this tutorial, we'll explore how to build an AI agent that integrates Together AI's powerful LLMs with Klavis MCP Servers, enabling seamless interaction with external services and APIs.\n",
        "\n",
        "This integration combines:\n",
        "- **Together AI**: High-performance open-source LLMs with function calling capabilities\n",
        "- **Klavis AI**: MCP (Model Context Protocol) servers for connecting to external tools and services\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before we begin, you'll need:\n",
        "\n",
        "- **Together AI API key** - Get yours at [together.ai](https://together.ai/)\n",
        "- **Klavis AI API key** - Get yours at [klavis.ai](https://klavis.ai/)\n",
        "\n",
        "Make sure to keep these API keys secure and never commit them to version control!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "!pip install -qU together requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"your-together-api-key-here\"  # Replace with your actual Together API key\n",
        "os.environ[\"KLAVIS_API_KEY\"] = \"your-klavis-api-key-here\"      # Replace with your actual Klavis API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Set up Klavis API\n",
        "\n",
        "Klavis API is built on REST principles and provides access to various MCP servers. Check out the [documentation](https://docs.klavis.ai/api-reference/introduction) if you're interested in learning more about the available services.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import urllib.parse\n",
        "from typing import Dict, Any, Optional, List\n",
        "import webbrowser\n",
        "\n",
        "class KlavisAPI:\n",
        "    \"\"\"API Client for Klavis API.\"\"\"\n",
        "    \n",
        "    def __init__(self, api_key: str, base_url: str = \"https://api.klavis.ai\"):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "    \n",
        "    def _make_request(self, method: str, endpoint: str, **kwargs) -> Dict[str, Any]:\n",
        "        \"\"\"Make HTTP request with error handling.\"\"\"\n",
        "        url = f\"{self.base_url}{endpoint}\"\n",
        "        response = requests.request(method, url, headers=self.headers, **kwargs)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    \n",
        "    def create_mcp_instance(self, server_name: str, user_id: str, platform_name: str) -> Dict[str, str]:\n",
        "        \"\"\"Create MCP server instance.\"\"\"\n",
        "        data = {\n",
        "            \"serverName\": server_name,\n",
        "            \"userId\": user_id,\n",
        "            \"platformName\": platform_name,\n",
        "            \"connectionType\": \"StreamableHttp\"\n",
        "        }\n",
        "        result = self._make_request(\"POST\", \"/mcp-server/instance/create\", json=data)\n",
        "        print(f\"‚úÖ Created {server_name} MCP instance\")\n",
        "        return {\n",
        "            'serverUrl': result['serverUrl'],\n",
        "            'instanceId': result['instanceId']\n",
        "        }\n",
        "    \n",
        "    def list_tools(self, server_url: str) -> Dict[str, Any]:\n",
        "        \"\"\"List all available tools for an MCP server.\"\"\"\n",
        "        params = {\"connection_type\": \"StreamableHttp\"}\n",
        "        encoded_url = urllib.parse.quote(server_url, safe='')\n",
        "        return self._make_request(\"GET\", f\"/mcp-server/list-tools/{encoded_url}\", params=params)\n",
        "    \n",
        "    def _convert_mcp_tools_to_openai_format(self, mcp_tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Convert MCP tools format to OpenAI function calling format.\"\"\"\n",
        "        openai_tools = []\n",
        "        \n",
        "        for tool in mcp_tools:\n",
        "            openai_tool = {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": tool.get(\"name\", \"\"),\n",
        "                    \"description\": tool.get(\"description\", \"\"),\n",
        "                    \"parameters\": tool.get(\"inputSchema\", {})\n",
        "                }\n",
        "            }\n",
        "            openai_tools.append(openai_tool)\n",
        "        \n",
        "        return openai_tools\n",
        "    \n",
        "    def call_tool(self, server_url: str, tool_name: str, \n",
        "                  tool_args: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Call tool on MCP server.\"\"\"\n",
        "        data = {\n",
        "            \"serverUrl\": server_url,\n",
        "            \"toolName\": tool_name,\n",
        "            \"toolArgs\": tool_args or {},\n",
        "            \"connectionType\": \"StreamableHttp\"\n",
        "        }\n",
        "        return self._make_request(\"POST\", \"/mcp-server/call-tool\", json=data)\n",
        "    \n",
        "    # Advanced use case if the MCP server requires OAuth authorization\n",
        "    def redirect_to_oauth(self, instance_id: str, server_name: str) -> None:\n",
        "        \"\"\"Open OAuth authorization URL in browser.\"\"\"\n",
        "        oauth_url = f\"{self.base_url}/oauth/{server_name.lower()}/authorize?instance_id={instance_id}\"\n",
        "        print(f\"üîê Opening OAuth authorization for {server_name}\")\n",
        "        print(f\"If you are not redirected automatically, please open this URL: {oauth_url}\")\n",
        "        webbrowser.open(oauth_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Create AI Agent with MCP Integration\n",
        "\n",
        "Now we'll create an intelligent agent that uses Together AI's powerful LLMs with Klavis MCP servers. This agent will:\n",
        "\n",
        "1. **Discover Tools**: Automatically find available tools from MCP servers\n",
        "2. **Function Calling**: Use Together AI's function calling capabilities\n",
        "3. **Tool Execution**: Execute tools through Klavis API\n",
        "4. **Smart Responses**: Generate intelligent responses based on tool results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, together_client, klavis_api_client, mcp_server_url, model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\"):\n",
        "        self.together = together_client\n",
        "        self.klavis = klavis_api_client\n",
        "        self.mcp_server_url = mcp_server_url\n",
        "        self.model = model\n",
        "        print(f\"ü§ñ Agent initialized with Together AI model: {self.model}\")\n",
        "    \n",
        "    def process_request(self, user_message):\n",
        "        \"\"\"Process a user request using Together AI + Klavis integration.\"\"\"\n",
        "        # 1. Get available tools from the MCP server\n",
        "        mcp_tools = self.klavis.list_tools(self.mcp_server_url)\n",
        "        tools = self.klavis._convert_mcp_tools_to_openai_format(mcp_tools.get('tools', []))\n",
        "        \n",
        "        # 2. Call Together AI LLM with available tools\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant with access to various tools.\"},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "        \n",
        "        response = self.together.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            tools=tools\n",
        "        )\n",
        "        \n",
        "        assistant_message = response.choices[0].message\n",
        "        messages.append(assistant_message)\n",
        "        \n",
        "        # 3. Execute any tool calls requested by the LLM\n",
        "        if assistant_message.tool_calls:\n",
        "            \n",
        "            # Execute each tool call\n",
        "            for tool_call in assistant_message.tool_calls:\n",
        "                tool_name = tool_call.function.name\n",
        "                tool_args = json.loads(tool_call.function.arguments)\n",
        "                \n",
        "                print(f\"üõ†Ô∏è Calling tool: {tool_name} with args: {tool_args}\")\n",
        "                \n",
        "                # Call tool via Klavis API\n",
        "                tool_result = self.klavis.call_tool(\n",
        "                    server_url=self.mcp_server_url,\n",
        "                    tool_name=tool_name,\n",
        "                    tool_args=tool_args\n",
        "                )\n",
        "                \n",
        "                # Add tool result to conversation\n",
        "                messages.append({\n",
        "                    \"role\": \"tool\",\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"content\": json.dumps(tool_result)\n",
        "                })\n",
        "            \n",
        "            # 4. Get final response from Together AI\n",
        "            final_response = self.together.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages\n",
        "            )\n",
        "            return final_response.choices[0].message.content\n",
        "        \n",
        "        # If no tools were needed, return the assistant's response directly\n",
        "        return assistant_message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Use Case 1: Summarize YouTube Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created YouTube MCP instance\n",
            "ü§ñ Agent initialized with Together AI model: meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
            "üõ†Ô∏è Calling tool: get_youtube_video_transcript with args: {'url': 'https://www.youtube.com/watch?v=TG6QOa2JJJQ'}\n",
            "The YouTube video \"Together AI CEO: Open Source Is the Future of AI\" features an interview with Vipul Ved Prakash, the CEO of Together AI, and Bucky Moore, a partner at Kleiner Perkins. The discussion revolves around Together AI's $102.5 million Series A fundraise, led by Kleiner Perkins, and the company's focus on open-source AI.\n",
            "\n",
            "Here is a comprehensive summary of the video with timestamps:\n",
            "\n",
            "* 0:00 - Introduction to the video and the guests\n",
            "* 0:30 - Discussion of Together AI's Series A fundraise and the company's mission\n",
            "* 1:45 - Vipul Ved Prakash explains the importance of open-source AI and how it can benefit the industry\n",
            "* 3:10 - Bucky Moore shares his perspective on the potential of open-source AI and its applications\n",
            "* 4:30 - The guests discuss the challenges and opportunities in the AI industry, including the need for more diverse and inclusive data sets\n",
            "* 5:50 - Vipul Ved Prakash talks about the company's plans for the future and how it aims to make AI more accessible and affordable for everyone\n",
            "* 6:40 - Conclusion and final thoughts from the guests\n",
            "\n",
            "Overall, the video provides insights into the future of AI and the potential of open-source AI, as well as the company's plans and goals.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from together import Together\n",
        "\n",
        "# Example YouTube video URL - replace with any video you'd like to analyze\n",
        "YOUTUBE_VIDEO_URL = \"https://www.youtube.com/watch?v=TG6QOa2JJJQ\"\n",
        "\n",
        "# 1. Initialize Together AI client and Klavis API client\n",
        "together_client = Together(api_key=os.getenv(\"TOGETHER_API_KEY\"))\n",
        "klavis_api_client = KlavisAPI(api_key=os.getenv(\"KLAVIS_API_KEY\"))\n",
        "\n",
        "# 2. Create a YouTube MCP server instance using Klavis API\n",
        "youtube_mcp_instance = klavis_api_client.create_mcp_instance(\n",
        "    server_name=\"YouTube\",\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        ")\n",
        "\n",
        "# 3. Create an agent with YouTube MCP server\n",
        "agent = Agent(\n",
        "    together_client=together_client, \n",
        "    klavis_api_client=klavis_api_client, \n",
        "    mcp_server_url=youtube_mcp_instance[\"serverUrl\"],\n",
        "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\n",
        ")\n",
        "\n",
        "# 4. Process the request\n",
        "response = agent.process_request(\n",
        "    f\"Please analyze this YouTube video and provide a comprehensive summary with timestamps: {YOUTUBE_VIDEO_URL}\"\n",
        ")\n",
        "\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Use Case 2: Send Email\n",
        "\n",
        "**Note**: Gmail integration requires OAuth authentication, so you'll need to authorize the application in your browser.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created Gmail MCP instance\n",
            "üîê Opening OAuth authorization for Gmail\n",
            "If you are not redirected automatically, please open this URL: https://api.klavis.ai/oauth/gmail/authorize?instance_id=d9d482b3-433a-4330-9a8b-9548c0b0a326\n"
          ]
        }
      ],
      "source": [
        "# Email configuration\n",
        "EMAIL_RECIPIENT = \"zihaolin@klavis.ai\"  # Replace with the recipient's email\n",
        "EMAIL_SUBJECT = \"Greetings from Together AI + Klavis Integration\"\n",
        "EMAIL_BODY = \"This is a test email sent using the Together AI and Klavis AI integration. The email was sent automatically by your AI agent!\"\n",
        "\n",
        "# 1. Create a Gmail MCP server instance using Klavis API\n",
        "gmail_mcp_instance = klavis_api_client.create_mcp_instance(\n",
        "    server_name=\"Gmail\",\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        ")\n",
        "\n",
        "# 2. Redirect to Gmail OAuth page for authorization\n",
        "klavis_api_client.redirect_to_oauth(gmail_mcp_instance[\"instanceId\"], \"Gmail\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Agent initialized with Together AI model: Qwen/Qwen2.5-72B-Instruct-Turbo\n",
            "üõ†Ô∏è Calling tool: send_email with args: {'body': 'This is a test email sent using the Together AI and Klavis AI integration. The email was sent automatically by your AI agent!', 'subject': 'Greetings from Together AI + Klavis Integration', 'to': ['zihaolin@klavis.ai']}\n",
            "The email has been sent successfully to zihaolin@klavis.ai with the subject 'Greetings from Together AI + Klavis Integration'. The email ID is 19776f818ce706db.\n"
          ]
        }
      ],
      "source": [
        "# After OAuth authorization is complete, create the Gmail agent\n",
        "gmail_agent = Agent(\n",
        "    together_client=together_client,\n",
        "    klavis_api_client=klavis_api_client,\n",
        "    mcp_server_url=gmail_mcp_instance[\"serverUrl\"],\n",
        "    model=\"Qwen/Qwen2.5-72B-Instruct-Turbo\"\n",
        ")\n",
        "\n",
        "# Send the email\n",
        "response = gmail_agent.process_request(\n",
        "    f\"Please send an email to {EMAIL_RECIPIENT} with the subject '{EMAIL_SUBJECT}' and the following body: '{EMAIL_BODY}'\"\n",
        ")\n",
        "\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "Congratulations! You've successfully built AI agents that integrate Together AI's powerful LLMs with Klavis MCP servers. Here's what we accomplished:\n",
        "\n",
        "### üöÄ Next Steps\n",
        "- **Explore More MCP Servers**: Try other available servers like Slack, Notion, CRM etc.\n",
        "- **Experiment with Different Models**: Test various Together AI models for different use cases.\n",
        "- **Build Complex Multi-Server Workflows**: Create sophisticated agents that combine multiple services\n",
        "- **Production Deployment**: Scale these patterns for production applications\n",
        "- **Custom MCP Servers**: Build your own MCP servers for proprietary systems\n",
        "\n",
        "### üîó Useful Resources\n",
        "- [Together AI Documentation](https://docs.together.ai/)\n",
        "- [Klavis AI Documentation](https://docs.klavis.ai/)\n",
        "- [MCP Protocol Specification](https://modelcontextprotocol.io/)\n",
        "- [Together AI Models](https://docs.together.ai/docs/inference-models)\n",
        "- [Klavis MCP Servers](https://docs.klavis.ai/mcp-servers)\n",
        "\n",
        "**Happy building with Together AI and Klavis!** üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
